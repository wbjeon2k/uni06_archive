//
// tokenizer.h - Version 1.0
//
// This file is created by Tsz-Chiu Au on 9/24/17.
//
// You are *not* allowed to modify this file, and
// you do *not* submit this file.
//

#ifndef ASSIGNMENT1_TOKENIZER_H
#define ASSIGNMENT1_TOKENIZER_H

#include <vector>
#include <string>
#include "Token.h"

using namespace std;

vector<Token> tokenize(const string &eqn);


#endif //ASSIGNMENT1_TOKENIZER_H
